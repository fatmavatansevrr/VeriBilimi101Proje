# -*- coding: utf-8 -*-
"""BinalarınEnerjiVerimliligi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fpa25Wnn6dJXxpJk11TR0RagIcc_hByw

1.Binaların Enerji Verimliliği
Problem tanımı ve amaç: Veri seti, simüle edilmiş 768 bina şeklinin yüzey/duvar/çatı alanı, cam alanı, cam alanı dağılımı ve yönü gibi özelliklerini içermektedir. Bu veriye dayanarak binanın ısıtma ve soğutma yükünü tahmin etmek amaçlanmaktadır. Çevre duyarlılığının çok önemli olduğu şu çağda halen yenilenebilir enerji kaynaklarına geçmediğimiz için karbon ayak izini azaltmak için süper bir danışmanlık girişimi olabilir.
> ***Specifically***:
* X1 Relative Compactness
* X2 Surface Area
* X3 Wall Area
* X4 Roof Area
* X5 Overall Height
* X6 Orientation
* X7 Glazing Area
* X8 Glazing Area Distribution
* y1 Heating Load
* y2 Cooling Load

Veri Seti Link: https://www.kaggle.com/elikplim/eergy-efficiency-dataset

Projelerden, ilginizi çeken veri setleri üzerinde bu derste öğrendiklerinizi uygulayıp github reposunun linkini paylaşın (derste öğrendiklerimizin dışında yeni şeyler denerseniz daha da iyi !)

Genel olarak yapacağınız adımlar şunlar olacak:

Kullanacağınız veriyi indirip, okumak
Verinizin içindeki eksik ve kategorik değişkenler ile ilgilenip modele besleyeceğimiz hale getirmek (derste gördüklerimizin üzerine de bir şeyler yapmanız hoşumuza gider demiştik, outlier'ları olan bir veride outlier'lar ile ilgili yaptıklarınızı görmek gibi şeyler olabilir mesela)
İlgilendiğiniz probleme göre error metriğine karar vermek (derste gördüğümüz RMSE-RMSLE gibi)
Verinizi train-validation-test diye bölmek (burada validation ve test'in gerçek hayatı yansıtması çok önemli)
Olabildiğince fazla model denemek ve metriğimizde en iyi yapanı seçmek

## Importing the libraries
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""## Importing the dataset"""

dataset = pd.read_csv('ENB2012_data.csv')
x = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

dataset.columns = ["Relative Compactness","Surface Area","Wall Area",
                "Roof Area", "Overall Height","Orientation","Glazing Area",
                "Glazing Area Distribution", "Heating Load", "Cooling Load"]

dataset.head()

#control the nulls
dataset.isnull().sum()

#categorical type check
dataset.info()

"""## Splitting the dataset into the Training set and Test set

"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)

"""## Models"""

#linear regression
from sklearn.linear_model import LinearRegression

lin_reg1 = LinearRegression()
lin_reg1.fit(x_train,y_train)
y_pred_lin_reg = lin_reg1.predict(x_test)

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

r2_score_lr = r2_score(y_pred_lin_reg,y_test)
print("Lineer Reg R2",r2_score_lr)
mse_lr = mean_squared_error(y_test, y_pred_lin_reg)
print("Mean Squared Linear",mse_lr)

#polynomial regression
from sklearn.preprocessing import PolynomialFeatures
poly_regressor = PolynomialFeatures(degree = 4)
x_poly = poly_regressor.fit_transform(x_train)
lin_reg_2 = LinearRegression()
lin_reg_2.fit(x_poly, y_train)
y_pred_plr = lin_reg_2.predict(poly_regressor.fit_transform(x_test))

r2_score_plr = r2_score(y_pred_plr,y_test)
print("Polynomial Reg R2",r2_score_plr)
mse_plr = mean_squared_error(y_test, y_pred_plr)
print("Mean Squared Linear",mse_plr)

#decision tree regression
from sklearn.tree import DecisionTreeRegressor
regressor = DecisionTreeRegressor(random_state = 0)
regressor.fit(x_train, y_train)
y_predict = regressor.predict(x_test)


r2_dt = r2_score(y_predict,y_test)
mse_dt = mean_squared_error(y_test, y_predict)
print("DesicionTree R2",r2_dt)
print("Mean Squared Decision Tree",mse_dt)

#random forest regression

from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)
regressor.fit(x,y)
y_predict_random_f = regressor.predict(x_test)

r2_random_f = r2_score(y_test, y_predict_random_f)
mse_random_f = mean_squared_error(y_test, y_predict_random_f)
print("RandomForest R2",r2_random_f)
print("Mean Squared Decision Tree",mse_random_f)

comparison = [
        [mse_lr,r2_score_lr]
        ,[mse_plr,r2_score_plr]
        ,[mse_dt,r2_dt]
        ,[mse_random_f,r2_random_f] ]
comparison = pd.DataFrame(data=comparison).transpose()
comparison.columns = ["Linear","Polynomial","DecisionTree","RandomForest"]
comparison

#The one whose R2 is closest to 1 is the most correct model to choose.
# Therefore RandomForest is the best model to choose from this model group.